{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f1b408-9328-4774-bf0a-ec3b7537a45e",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3712572c-4c84-40a5-bd2e-5bc85dbae9ec",
   "metadata": {},
   "source": [
    "#### explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29f03e-4b74-47ff-bb41-de01f26c3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# \n",
    "X = pd.read_csv(\"./data/dataTrain.csv\", header=0, usecols=['electronegativity', 'd orbital of metal', 'group', 'radius/pm', 'first ionization energy'])\n",
    "y = pd.read_csv(\"./Data/dataTrain.csv\", header=0, usecols= ['1V-ORR'])\n",
    "\n",
    "\n",
    "#print(X['electronegativity'])\n",
    "#print(y['2V-OER'])\n",
    "plt.figure(figsize=(14, 2))\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.scatter(X['electronegativity'], y['1V-ORR'])\n",
    "plt.xlabel('electronegativity')\n",
    "plt.ylabel('1V-ORR')\n",
    "\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.scatter(X['d orbital of metal'], y['1V-ORR'])\n",
    "plt.xlabel('d orbital of metal')\n",
    "\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.scatter(X['group'], y['1V-ORR'])\n",
    "plt.xlabel('group')\n",
    "\n",
    "plt.subplot(1, 5, 4)\n",
    "plt.scatter(X['radius/pm'], y['1V-ORR'])\n",
    "plt.xlabel('radius/pm')\n",
    "\n",
    "plt.subplot(1, 5, 5)\n",
    "plt.scatter(X['first ionization energy'], y['1V-ORR'])\n",
    "plt.xlabel('first ionization energy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212288d9-8470-4dbc-9dab-a88d223a4e28",
   "metadata": {},
   "source": [
    "#### Prepare data for Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e34157-1d77-4e0d-a2f4-4705f2ecf02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8862, -1.3299, -1.2850, -0.2905, -0.9610]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as td\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def loaddata(pathway, Ylabel, i, j, k):\n",
    "    df = pd.read_csv(pathway)\n",
    "    Xfeatures = ['electronegativity', 'd orbital of metal', 'group', 'radius/pm', 'first ionization energy']\n",
    "    x = df[Xfeatures].values\n",
    "    y = df[Ylabel].values\n",
    "\n",
    "    label0, label1, label2 = x[i], x[j], x[k]\n",
    "    label0, label1, label2 = torch.Tensor(label0).float(), torch.Tensor(label1).float(), torch.Tensor(label2).float()\n",
    "    label0 = label0.reshape(1, 1, 5).float()\n",
    "    label1 = label1.reshape(1, 1, 5).float()\n",
    "    label2 = label2.reshape(1, 1, 5).float()\n",
    "    print(label0)\n",
    "    \n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=10)\n",
    "    \n",
    "    # create loader for the training data and labels\n",
    "    train_x = torch.Tensor(X_train).float()\n",
    "    train_x = train_x.reshape(12, 1, 5).float()\n",
    "    train_y = torch.Tensor(y_train).float()\n",
    "    train_data = td.TensorDataset(train_x, train_y)\n",
    "    train_loader = td.DataLoader(train_data, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "    # create loader for the test data and labels\n",
    "    test_x = torch.Tensor(X_test).float()\n",
    "    test_x = test_x.reshape(2, 1, 5).float()\n",
    "    test_y = torch.Tensor(y_test).float()\n",
    "    test_data = td.TensorDataset(test_x, test_y)\n",
    "    test_loader = td.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "    return train_loader, test_loader, label0, label1, label2\n",
    "\n",
    "pathway = \"./Data/dataTrain.csv\"\n",
    "Ylabel = \"1V-ORR\"\n",
    "train_loader, test_loader, label0, label1, label2 = loaddata(pathway, Ylabel, 1, 2, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684f11a-f6bc-410d-8852-ce6beb1cf5b0",
   "metadata": {},
   "source": [
    "#### Define the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addc9c4c-6443-44fc-b65c-9064cdcf4dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNNet(\n",
      "  (conv0): Conv1d_same_padding(\n",
      "    (conv1d): Conv1d(4, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv1): Conv1d_same_padding(\n",
      "    (conv1d): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Conv1d_same_padding(\n",
      "    (conv1d): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv3): Conv1d_same_padding(\n",
      "    (conv1d): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv4): Conv1d_same_padding(\n",
      "    (conv1d): Conv1d(16, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (dense0): Linear(in_features=40, out_features=32, bias=False)\n",
      "  (dense1): Linear(in_features=32, out_features=16, bias=False)\n",
      "  (dense2): Linear(in_features=16, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Conv1d_same_padding(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size, strides=1, dilation=1):\n",
    "        super(Conv1d_same_padding, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.dilation = dilation\n",
    "        self.conv1d = nn.Conv1d(inplanes, planes, kernel_size, strides, bias=False)\n",
    "        nn.init.xavier_uniform_(self.conv1d.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_rows = x.size(2)\n",
    "        out_rows = (input_rows + self.strides -1) // self.strides\n",
    "        padding_rows = max(0, (out_rows - 1) * self.strides + (self.kernel_size - 1) * self.dilation + 1 - input_rows)\n",
    "        x = F.pad(x, pad=(0, padding_rows), mode=\"constant\")\n",
    "        x = self.conv1d(x)\n",
    "        return x\n",
    "\n",
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNet, self).__init__()\n",
    "\n",
    "        self.conv0 = Conv1d_same_padding(4, 16, 1)\n",
    "        self.conv1 = Conv1d_same_padding(16, 16, 1)\n",
    "        self.conv2 = Conv1d_same_padding(16, 16, 1)\n",
    "        self.conv3 = Conv1d_same_padding(16, 16, 1)\n",
    "        self.conv4 = Conv1d_same_padding(16, 8, 1)\n",
    "\n",
    "        self.dense0 = nn.Linear(40, 32, bias=False)\n",
    "        self.dense1 = nn.Linear(32, 16, bias=False)\n",
    "        self.dense2 = nn.Linear(16, 1, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.dense0.weight)\n",
    "        nn.init.xavier_uniform_(self.dense1.weight)\n",
    "        nn.init.xavier_uniform_(self.dense2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        x = torch.flatten(x)\n",
    "        \n",
    "        x = F.relu(self.dense0(x))\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "model = CNNNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4bd9b-8df3-4082-b7bf-3d4f94359ad9",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40cdd3bb-eb12-4ec6-b883-3b0899a40a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, pathway, optimizer, i, j, k):\n",
    "    # set the model to train the model\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    train_loader, test_loader, label0, label1, label2 = loaddata(pathway, Ylabel, i, j, k)\n",
    "    loss_criteria = nn.MSELoss()\n",
    "    index = 0\n",
    "    for datax, target in train_loader:\n",
    "        index += 1\n",
    "        data = torch.cat([datax, label0, label1, label2], dim=1)\n",
    "        # feed forward\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_criteria(out, target)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # backpropagate \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = train_loss / (index + 1)\n",
    "    print(\"Training set: Average loss: {:.6f}\".format(avg_loss))\n",
    "    return avg_loss\n",
    "\n",
    "def test(model, pathway, i, j, k):\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    train_loader, test_loader, label0, label1, label2 = loaddata(pathway, Ylabel, i, j, k)\n",
    "    loss_criteria = nn.MSELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        index = 0\n",
    "        for datax, target in test_loader:\n",
    "            index += 1\n",
    "            data = torch.cat([datax, label0, label1, label2], dim=1)\n",
    "            out = model(data)\n",
    "            test_loss += loss_criteria(out, target).item()\n",
    "\n",
    "        avg_loss = test_loss /(index+1)\n",
    "        print(\"Test set: Average loss: {:.6f}\".format(avg_loss))\n",
    "        return avg_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc012a-0381-42b2-ac28-55a05e554581",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def train(model, train_loader, optimizer, label0, label1, label2):\n",
    "    # set the model to train the model\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    loss_criteria = nn.MSELoss()\n",
    "    index = 0\n",
    "    for datax, target in train_loader:\n",
    "        index += 1\n",
    "        data = torch.cat([datax, label0, label1, label2], dim=1)\n",
    "        # feed forward\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_criteria(out, target)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # backpropagate \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = train_loss / (index + 1)\n",
    "    print(\"Training set: Average loss: {:.6f}\".format(avg_loss))\n",
    "    return avg_loss\n",
    "    \n",
    "def test(model, test_loader, label0, label1, label2):\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    loss_criteria = nn.MSELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        index = 0\n",
    "        for datax, target in test_loader:\n",
    "            index += 1\n",
    "            data = torch.cat([datax, label0, label1, label2], dim=1)\n",
    "            out = model(data)\n",
    "            test_loss += loss_criteria(out, target).item()\n",
    "\n",
    "        avg_loss = test_loss /(index+1)\n",
    "        print(\"Test set: Average loss: {:.6f}\".format(avg_loss))\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b545bf02-465e-4187-b8a7-73f6f8a6ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Training set: Average loss: 2.664845\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Test set: Average loss: 3.332148\n",
      "Epoch: 2\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Training set: Average loss: 2.664845\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Test set: Average loss: 3.332148\n",
      "Epoch: 3\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Training set: Average loss: 2.664845\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Test set: Average loss: 3.332148\n",
      "Epoch: 4\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Training set: Average loss: 2.664845\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Test set: Average loss: 3.332148\n",
      "Epoch: 5\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Training set: Average loss: 2.664845\n",
      "tensor([[[-0.6303, -0.9945, -0.9334, -0.6453, -1.0398]]])\n",
      "Test set: Average loss: 3.332148\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# use an \"Adam\" optimizer to adjust weights\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# model and datafile\n",
    "train_loader, test_loader, label0, label1, label2 = loaddata(pathway, Ylabel, 3, 4, 13)\n",
    "model = CNNNet()\n",
    "\n",
    "# track metrics\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, label0, label1, label2)\n",
    "    test_loss = test(model, test_loader, label0, label1, label2)\n",
    "\n",
    "    epoch_nums.append(epoch)\n",
    "    training_loss.append(train_loss)\n",
    "    validation_loss.append(test_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648386c-1e4a-450f-bfc5-44442cea650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2fb4b-7911-4515-b13d-782d6f9f1f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
